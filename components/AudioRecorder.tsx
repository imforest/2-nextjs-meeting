"use client";

import { useState, useRef, useCallback, useEffect } from "react";

interface AudioRecorderProps {
  onTranscript?: (text: string) => void;
  onRecordingComplete?: (audioBlob: Blob) => void;
}

type RecordingState = "idle" | "recording" | "paused";

export default function AudioRecorder({
  onTranscript,
  onRecordingComplete,
}: AudioRecorderProps) {
  const [state, setState] = useState<RecordingState>("idle");
  const [duration, setDuration] = useState(0); // ì´ˆ ë‹¨ìœ„
  const [error, setError] = useState<string | null>(null);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [transcript, setTranscript] = useState<string>("");
  const [devices, setDevices] = useState<MediaDeviceInfo[]>([]);
  const [selectedDeviceId, setSelectedDeviceId] = useState<string>("");
  const [loadingDevices, setLoadingDevices] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const intervalRef = useRef<NodeJS.Timeout | null>(null);
  const startTimeRef = useRef<number>(0);
  const pausedTimeRef = useRef<number>(0);
  const recorderMimeTypeRef = useRef<string>("");
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const rafRef = useRef<number | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);

  // ì‹œê°„ í¬ë§·íŒ… (HH:MM:SS)
  const formatTime = (seconds: number): string => {
    const hrs = Math.floor(seconds / 3600);
    const mins = Math.floor((seconds % 3600) / 60);
    const secs = seconds % 60;
    return `${String(hrs).padStart(2, "0")}:${String(mins).padStart(
      2,
      "0"
    )}:${String(secs).padStart(2, "0")}`;
  };

  const resetAudioGraph = () => {
    if (rafRef.current) {
      cancelAnimationFrame(rafRef.current);
      rafRef.current = null;
    }
    try {
      sourceRef.current?.disconnect();
      analyserRef.current?.disconnect();
    } catch {}
    sourceRef.current = null;
    analyserRef.current = null;
    if (audioContextRef.current) {
      audioContextRef.current.close().catch(() => {});
      audioContextRef.current = null;
    }
  };

  const drawWave = useCallback(() => {
    const canvas = canvasRef.current;
    const analyser = analyserRef.current;
    if (!canvas || !analyser) return;
    const ctx = canvas.getContext("2d");
    if (!ctx) return;
    const width = canvas.width;
    const height = canvas.height;
    analyser.fftSize = 2048;
    const bufferLength = analyser.fftSize;
    const dataArray = new Uint8Array(bufferLength);

    const render = () => {
      analyser.getByteTimeDomainData(dataArray);
      ctx.clearRect(0, 0, width, height);
      // mid line
      ctx.strokeStyle =
        getComputedStyle(document.documentElement).getPropertyValue(
          "--notion-border"
        ) || "#e5e7eb";
      ctx.lineWidth = 1;
      ctx.beginPath();
      ctx.moveTo(0, height / 2);
      ctx.lineTo(width, height / 2);
      ctx.stroke();

      // waveform
      ctx.lineWidth = 2;
      ctx.strokeStyle =
        getComputedStyle(document.documentElement).getPropertyValue(
          "--notion-blue"
        ) || "#3b82f6";
      ctx.beginPath();
      const sliceWidth = width / bufferLength;
      let x = 0;
      for (let i = 0; i < bufferLength; i++) {
        const v = dataArray[i] / 128.0; // 0..2
        const y = (v * height) / 2;
        if (i === 0) ctx.moveTo(x, y);
        else ctx.lineTo(x, y);
        x += sliceWidth;
      }
      ctx.stroke();
      rafRef.current = requestAnimationFrame(render);
    };
    render();
  }, []);

  const loadInputDevices = useCallback(async () => {
    if (!navigator.mediaDevices?.enumerateDevices) return;
    setLoadingDevices(true);
    try {
      const list = await navigator.mediaDevices.enumerateDevices();
      const mics = list.filter((d) => d.kind === "audioinput");
      setDevices(mics);
      if (!selectedDeviceId && mics.length > 0) {
        setSelectedDeviceId(mics[0].deviceId);
      }
    } catch {
      // ignore
    } finally {
      setLoadingDevices(false);
    }
  }, [selectedDeviceId]);

  useEffect(() => {
    // ê¶Œí•œì´ ì—†ëŠ” ìƒíƒœì—ì„œë„ ë¹„ì–´ìˆëŠ” labelì´ ë°˜í™˜ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
    // ìµœì´ˆ 1íšŒ ì‹œë„ í›„, startRecordingì—ì„œ ê¶Œí•œ í—ˆìš© ë’¤ ë‹¤ì‹œ ë¡œë“œ
    loadInputDevices();
  }, [loadInputDevices]);

  const mapGetUserMediaError = (err: unknown): string => {
    const name = (err as DOMException)?.name;
    switch (name) {
      case "NotFoundError":
      case "DevicesNotFoundError":
        return "ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Windowsì˜ 'ì†Œë¦¬ ì„¤ì • > ì…ë ¥'ì—ì„œ ë§ˆì´í¬ê°€ ì—°ê²°/í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.";
      case "NotAllowedError":
      case "SecurityError":
        return "ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì£¼ì†Œì°½ì˜ ê¶Œí•œ ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ 'í—ˆìš©'ìœ¼ë¡œ ë³€ê²½í•œ ë’¤ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.";
      case "NotReadableError":
        return "ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì´ ë§ˆì´í¬ë¥¼ ì‚¬ìš© ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í™”ìƒíšŒì˜/ë…¹ìŒ ì•±ì„ ì¢…ë£Œí•œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.";
      case "OverconstrainedError":
        return "ì„ íƒí•œ ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¥ì¹˜ë¥¼ ì„ íƒí•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.";
      case "TypeError":
        return "getUserMediaë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. HTTPS ë˜ëŠ” localhostì—ì„œ ì ‘ì†í–ˆëŠ”ì§€, ì§€ì›ë˜ëŠ” ë¸Œë¼ìš°ì €ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.";
      default:
        return err instanceof Error
          ? err.message
          : "ë§ˆì´í¬ ì ‘ê·¼ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
    }
  };

  // ë…¹ìŒ ì‹œì‘
  const startRecording = useCallback(async () => {
    try {
      setError(null);
      setTranscript(""); // ì´ì „ ë³€í™˜ ê²°ê³¼ ì´ˆê¸°í™”
      setDuration(0);
      pausedTimeRef.current = 0;
      if (!navigator.mediaDevices?.getUserMedia) {
        throw new DOMException("getUserMedia not supported", "TypeError");
      }

      const constraints: MediaStreamConstraints = selectedDeviceId
        ? { audio: { deviceId: { exact: selectedDeviceId } } }
        : { audio: true };

      const stream = await navigator.mediaDevices.getUserMedia(constraints);
      streamRef.current = stream;

      // ë¸Œë¼ìš°ì € ì§€ì› mimeType íƒì§€
      const candidateTypes = [
        "audio/webm;codecs=opus",
        "audio/webm",
        "audio/ogg;codecs=opus",
        "audio/mp4",
      ];
      let chosenType = "";
      if (
        typeof (window as any).MediaRecorder?.isTypeSupported === "function"
      ) {
        for (const t of candidateTypes) {
          if ((window as any).MediaRecorder.isTypeSupported(t)) {
            chosenType = t;
            break;
          }
        }
      }

      // mimeTypeì´ ë¯¸ì§€ì›ì´ë©´ ì˜µì…˜ ì—†ì´ ìƒì„± (ë¸Œë¼ìš°ì €ê°€ ìë™ ì„ íƒ)
      const mediaRecorder =
        chosenType !== ""
          ? new MediaRecorder(stream, { mimeType: chosenType })
          : new MediaRecorder(stream);

      recorderMimeTypeRef.current = mediaRecorder.mimeType || chosenType || "";
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      // ì˜¤ë””ì˜¤ ê·¸ë˜í”„ êµ¬ì„± & ì›¨ì´ë¸Œ ì‹œì‘
      const AudioCtx =
        (window as any).AudioContext || (window as any).webkitAudioContext;
      const audioCtx = new AudioCtx();
      audioContextRef.current = audioCtx;
      const source = audioCtx.createMediaStreamSource(stream);
      sourceRef.current = source;
      const analyser = audioCtx.createAnalyser();
      analyserRef.current = analyser;
      source.connect(analyser);
      drawWave();

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          chunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onstop = async () => {
        if (streamRef.current) {
          streamRef.current.getTracks().forEach((track) => track.stop());
          streamRef.current = null;
        }

        resetAudioGraph();

        const blobType =
          recorderMimeTypeRef.current ||
          (chunksRef.current[0] && (chunksRef.current[0] as any).type) ||
          "audio/webm";
        const audioBlob = new Blob(chunksRef.current, { type: blobType });
        if (onRecordingComplete) {
          onRecordingComplete(audioBlob);
        }

        // ìë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
        await transcribeAudio(audioBlob);

        // ë…¹ìŒ ì¢…ë£Œ í›„ ìƒíƒœ ì´ˆê¸°í™”
        setDuration(0);
        pausedTimeRef.current = 0;
      };

      mediaRecorder.start();
      setState("recording");
      startTimeRef.current = Date.now() - pausedTimeRef.current * 1000;

      // ì‹œê°„ ì—…ë°ì´íŠ¸
      intervalRef.current = setInterval(() => {
        const elapsed = Math.floor((Date.now() - startTimeRef.current) / 1000);
        setDuration(elapsed);
      }, 1000);
      // ê¶Œí•œ í—ˆìš© í›„ ì¥ì¹˜ ëª©ë¡ ë‹¤ì‹œ ë¡œë“œ
      loadInputDevices();
    } catch (err) {
      setError(mapGetUserMediaError(err));
    }
  }, [onRecordingComplete, selectedDeviceId, loadInputDevices]);

  // ì¼ì‹œì •ì§€
  const pauseRecording = useCallback(() => {
    if (mediaRecorderRef.current && state === "recording") {
      mediaRecorderRef.current.pause();
      setState("paused");
      pausedTimeRef.current = duration;
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
        intervalRef.current = null;
      }
    }
  }, [state, duration]);

  // ì¬ê°œ
  const resumeRecording = useCallback(() => {
    if (mediaRecorderRef.current && state === "paused") {
      mediaRecorderRef.current.resume();
      setState("recording");
      startTimeRef.current = Date.now() - pausedTimeRef.current * 1000;

      intervalRef.current = setInterval(() => {
        const elapsed = Math.floor((Date.now() - startTimeRef.current) / 1000);
        setDuration(elapsed);
      }, 1000);
    }
  }, [state]);

  // ë…¹ìŒ ì¢…ë£Œ
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current) {
      mediaRecorderRef.current.stop();
      setState("idle");
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
        intervalRef.current = null;
      }
      pausedTimeRef.current = 0;
      resetAudioGraph();
    }
  }, []);

  // ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
  const transcribeAudio = async (audioBlob: Blob) => {
    setIsTranscribing(true);
    setError(null);

    try {
      // FormData ìƒì„±
      const formData = new FormData();
      const ext = recorderMimeTypeRef.current.includes("ogg")
        ? "ogg"
        : recorderMimeTypeRef.current.includes("mp4")
        ? "mp4"
        : "webm";
      formData.append("audio", audioBlob, `recording.${ext}`);

      const response = await fetch("/api/transcribe", {
        method: "POST",
        body: formData,
      });

      if (!response.ok) {
        const errorData = await response.json();
        throw new Error(errorData.error || "ë³€í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
      }

      const data = await response.json();
      const transcribedText = data.text || "";

      setTranscript(transcribedText);
      if (onTranscript) {
        onTranscript(transcribedText);
      }
    } catch (err) {
      setError(
        err instanceof Error ? err.message : "ìŒì„± ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
      );
    } finally {
      setIsTranscribing(false);
    }
  };

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
      }
      resetAudioGraph();
    };
  }, []);

  return (
    <div className="w-full">
      {/* ë…¹ìŒ ì»¨íŠ¸ë¡¤ */}
      <div className="bg-[var(--notion-bg)] border border-[var(--notion-border)] rounded-lg p-6">
        {/* ì¥ì¹˜ ì„ íƒ */}
        <div className="mb-4 flex items-center gap-2">
          <label
            className="text-sm"
            style={{ color: "var(--notion-text-secondary)" }}
          >
            ì…ë ¥ ì¥ì¹˜
          </label>
          <select
            value={selectedDeviceId}
            onChange={(e) => setSelectedDeviceId(e.target.value)}
            className="px-2 py-1 border rounded text-sm"
            style={{
              borderColor: "var(--notion-border)",
              color: "var(--notion-text)",
              backgroundColor: "var(--notion-bg)",
            }}
          >
            {devices.length === 0 && <option value="">ë§ˆì´í¬ ì—†ìŒ</option>}
            {devices.map((d) => (
              <option key={d.deviceId} value={d.deviceId}>
                {d.label || "ë§ˆì´í¬"}
              </option>
            ))}
          </select>
          <button
            type="button"
            onClick={loadInputDevices}
            className="px-2 py-1 text-sm border rounded"
            style={{ borderColor: "var(--notion-border)" }}
            disabled={loadingDevices}
            title="ì¥ì¹˜ ìƒˆë¡œê³ ì¹¨"
          >
            {loadingDevices ? "ìƒˆë¡œê³ ì¹¨..." : "ìƒˆë¡œê³ ì¹¨"}
          </button>
        </div>

        {/* ì‹œê°„ í‘œì‹œ */}
        <div className="text-center mb-6">
          <div
            className="text-4xl font-mono font-semibold mb-2"
            style={{ color: "var(--notion-text)" }}
          >
            {formatTime(duration)}
          </div>
          <div
            className="text-sm"
            style={{ color: "var(--notion-text-secondary)" }}
          >
            {state === "recording" && "ğŸ”´ ë…¹ìŒ ì¤‘..."}
            {state === "paused" && "â¸ ì¼ì‹œì •ì§€"}
            {state === "idle" && "â¹ ë…¹ìŒ ëŒ€ê¸°"}
          </div>
        </div>

        {/* ì›¨ì´ë¸Œ í‘œì‹œ */}
        <div className="mb-6">
          <canvas
            ref={canvasRef}
            width={800}
            height={120}
            className="w-full h-[120px] rounded border"
            style={{
              borderColor: "var(--notion-border)",
              backgroundColor: "var(--notion-bg)",
            }}
          />
        </div>

        {/* ë²„íŠ¼ ê·¸ë£¹ */}
        <div className="flex items-center justify-center gap-3">
          {state === "idle" && (
            <button
              onClick={startRecording}
              className="px-6 py-3 bg-red-500 hover:bg-red-600 text-white rounded-lg font-medium transition-colors shadow-sm"
            >
              ğŸ¤ ë…¹ìŒ ì‹œì‘
            </button>
          )}

          {state === "recording" && (
            <>
              <button
                onClick={pauseRecording}
                className="px-6 py-3 bg-yellow-500 hover:bg-yellow-600 text-white rounded-lg font-medium transition-colors shadow-sm"
              >
                â¸ ì¼ì‹œì •ì§€
              </button>
              <button
                onClick={stopRecording}
                className="px-6 py-3 bg-red-500 hover:bg-red-600 text-white rounded-lg font-medium transition-colors shadow-sm"
              >
                â¹ ë…¹ìŒ ì¢…ë£Œ
              </button>
            </>
          )}

          {state === "paused" && (
            <>
              <button
                onClick={resumeRecording}
                className="px-6 py-3 bg-green-500 hover:bg-green-600 text-white rounded-lg font-medium transition-colors shadow-sm"
              >
                â–¶ ë‹¤ì‹œ ì‹œì‘
              </button>
              <button
                onClick={stopRecording}
                className="px-6 py-3 bg-red-500 hover:bg-red-600 text-white rounded-lg font-medium transition-colors shadow-sm"
              >
                â¹ ë…¹ìŒ ì¢…ë£Œ
              </button>
            </>
          )}
        </div>

        {/* ì—ëŸ¬ ë©”ì‹œì§€ */}
        {error && (
          <div className="mt-4 p-3 bg-red-50 border border-red-200 rounded text-red-700 text-sm">
            {error}
          </div>
        )}

        {/* ë³€í™˜ ì¤‘ í‘œì‹œ */}
        {isTranscribing && (
          <div className="mt-4 p-3 bg-blue-50 border border-blue-200 rounded text-blue-700 text-sm flex items-center gap-2">
            <span className="animate-spin">â³</span>
            <span>ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ì¤‘...</span>
          </div>
        )}

        {/* ë³€í™˜ëœ í…ìŠ¤íŠ¸ */}
        {transcript && (
          <div className="mt-4 p-4 bg-[var(--notion-hover)] rounded-lg border border-[var(--notion-border)]">
            <div
              className="text-sm font-medium mb-2"
              style={{ color: "var(--notion-text)" }}
            >
              ë³€í™˜ëœ í…ìŠ¤íŠ¸:
            </div>
            <div
              className="text-sm whitespace-pre-wrap"
              style={{ color: "var(--notion-text)" }}
            >
              {transcript}
            </div>
          </div>
        )}
      </div>
    </div>
  );
}
